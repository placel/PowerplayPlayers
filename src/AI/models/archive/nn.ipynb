{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set at program startup\n",
    "    print(e)\n",
    "\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/combined_team_player_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[:len(df)//2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['positionCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df['positionCode'], prefix='positionCode')\n",
    "\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "df = df.drop('positionCode', axis=1)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(df['homeRoad'], prefix='homeRoad')\n",
    "\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "df = df.drop('homeRoad', axis=1)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(df['homeRoad_opponent'], prefix='homeRoad_opponent')\n",
    "\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "df = df.drop('homeRoad_opponent', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce down to binary classes\n",
    "We want to know if the player scores a powerplay point or not. It's quite rare for a player to score 2 or more (although it may be important information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ppPoint_scored'] = df['ppPoints'].map(lambda x: 1 if x >= 1 else 0)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_len = len(df.columns)\n",
    "count = 0\n",
    "for i in range(16):\n",
    "    print(df.columns.to_list()[count:count+10])\n",
    "    if count >= col_len:\n",
    "        break\n",
    "    count = count + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['gameId', 'penaltyKillNetPct', 'powerPlayNetPct', 'regulationAndOtWins', 'teamFullName', 'teamId', 'ties', 'winsInShootout', \n",
    "             'ppOpportunitiesPerGame', 'shGoalsAgainstPerGame', 'netPenalties', 'netPenaltiesPer60', 'pkNetGoalsPerGame', 'opponentTeamAbbrev_opponent',\n",
    "             'penaltyKillNetPct_opponent', 'regulationAndOtWins_opponent', 'teamFullName_opponent', 'teamId_opponent', 'ties_opponent', 'winsInShootout_opponent',\n",
    "             'ppNetGoalsPerGame_opponent', 'ppOpportunitiesPerGame_opponent', 'shGoalsAgainstPerGame_opponent', 'netPenaltiesPer60_opponent',\n",
    "             'netPenalties_opponent', 'pkNetGoalsPerGame_opponent', 'ppGoalsAgainstPerGame_opponent', 'shGoalsForPerGame_opponent', 'timesShorthandedPerGame_opponent',\n",
    "             'teamAbbrev_opponent', 'lastName', 'playerId', 'pointsPerGame', 'shootsCatches', 'skaterFullName', 'gameDate', 'opponentTeamAbbrev', \n",
    "             'ppGoalsForPer60', 'ppIndividualSatForPer60', 'ppPointsPer60', 'ppPrimaryAssistsPer60', 'ppSecondaryAssistsPer60', 'ppShotsPer60', 'ppTimeOnIcePctPerGame',\n",
    "             'ppTimeOnIcePerGame', 'goalsForPerGame', 'teamAbbrev', 'gameDate_opponent', 'gameDate', 'powerPlayGoalsFor', 'ppGoals'\n",
    "            ]\n",
    "\n",
    "print(len(to_remove))\n",
    "all_cols = df.columns.to_list()\n",
    "\n",
    "print(len(all_cols))\n",
    "X_cols = list(set(all_cols) - set(to_remove))\n",
    "\n",
    "X = df[X_cols]\n",
    "print(len(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_variable = 'ppPoint_scored'\n",
    "\n",
    "# Step 2: Inspect class distribution\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(df[target_variable].value_counts())\n",
    "\n",
    "# Step 3: Split features and target variable\n",
    "X = X.drop(target_variable, axis=1)\n",
    "y = df[target_variable]\n",
    "\n",
    "# Step 4: Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Step 5: Use the resampled dataset\n",
    "# For example, you can split the resampled dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cols = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = X_test.values\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping for LSTM\n",
    "T = 1 # Each row is per game, so we are treating each row as a time step\n",
    "X_train = X_train.reshape(X_train.shape[0], T, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], T, X_test.shape[1])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # Dropout(dropout_rate),\n",
    "    LSTM(128, input_shape=(X_train.shape[0], T, X_train.shape[2])),\n",
    "    # LSTM(128, return_sequences=True, input_shape=(X_train.shape[0], T, X_train.shape[2])),\n",
    "    # LSTM(128, return_sequences=True, input_shape=(X_train.shape[0], T, X_train.shape[2])),\n",
    "    # LSTM(128, return_sequences=True, input_shape=(X_train.shape[0], T, X_train.shape[2])),\n",
    "    # LSTM(128, return_sequences=True, input_shape=(X_train.shape[0], T, X_train.shape[2])),\n",
    "    # LSTM(128, activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # Dropout(dropout_rate),\n",
    "    Dense(128, activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # Dropout(dropout_rate),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[tf.keras.metrics.Precision(), 'accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=128, verbose=1, callbacks=[callback], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Adjust the threshold\n",
    "threshold = 0.9 # You can experiment with different threshold values\n",
    "y_pred_labels = (y_pred_probs > threshold).astype(int)\n",
    "\n",
    "print(f'threshold of {threshold*100}%')\n",
    "print(classification_report(y_test, y_pred_labels))\n",
    "\n",
    "y_pred = model.predict(X_test) \n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "print('Regular threshold')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['precision'], label='Training Precision')\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(y_pred, label='Testing Precision')\n",
    "# plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player List Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Averages of Players and Teams, then combine into 1 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df = pd.read_csv('../data/database/player-database.csv')\n",
    "team_df = pd.read_csv('../data/database/team-database.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the average of each players stats for the last 5 games, then take the last occurance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have loaded your dataframe into a variable called 'nhl_stats_df'\n",
    "\n",
    "# Sort the dataframe by player and date\n",
    "nhl_stats_df = player_df.sort_values(by=['playerId', 'gameDate'])\n",
    "\n",
    "# Define a function to calculate the rolling average for numeric columns\n",
    "def calc_rolling_avg(group):\n",
    "    return group.rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Split the dataframe into numeric and non-numeric parts\n",
    "numeric_columns = nhl_stats_df.select_dtypes(include='number').columns\n",
    "numeric_columns = numeric_columns.drop('gameId')\n",
    "non_numeric_columns = [col for col in nhl_stats_df.columns if col not in numeric_columns]\n",
    "\n",
    "# Calculate the rolling average for numeric columns for each player\n",
    "rolling_avg_numeric_df = nhl_stats_df.groupby('playerId', group_keys=False)[numeric_columns].apply(calc_rolling_avg)\n",
    "\n",
    "# Merge rolling average with non-numeric columns\n",
    "rolling_avg_df = pd.concat([nhl_stats_df[non_numeric_columns], rolling_avg_numeric_df], axis=1)\n",
    "player_df = rolling_avg_df.groupby('playerId').tail(1) ## get the last game for each player \n",
    "player_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the average for each teams stats over the last 5 games, and return the last occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have loaded your dataframe into a variable called 'nhl_stats_df'\n",
    "\n",
    "# Sort the dataframe by player and date\n",
    "nhl_stats_df = team_df.sort_values(by=['teamId', 'gameDate'])\n",
    "\n",
    "# Define a function to calculate the rolling average for numeric columns\n",
    "def calc_rolling_avg(group):\n",
    "    return group.rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Split the dataframe into numeric and non-numeric parts\n",
    "numeric_columns = nhl_stats_df.select_dtypes(include='number').columns\n",
    "numeric_columns = numeric_columns.drop('gameId')\n",
    "non_numeric_columns = [col for col in nhl_stats_df.columns if col not in numeric_columns]\n",
    "\n",
    "# Calculate the rolling average for numeric columns for each player\n",
    "rolling_avg_numeric_df = nhl_stats_df.groupby('teamId', group_keys=False)[numeric_columns].apply(calc_rolling_avg)\n",
    "\n",
    "# Merge rolling average with non-numeric columns\n",
    "rolling_avg_df = pd.concat([nhl_stats_df[non_numeric_columns], rolling_avg_numeric_df], axis=1)\n",
    "team_df = rolling_avg_df.groupby('teamId').tail(1) ## Get the last occurance of each teams stats and save them into the orginal team_df\n",
    "team_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group player stats, team stats, and opposing team stats into one dataframe for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhl_teams = {\n",
    "    'Anaheim Ducks': 'ANA',\n",
    "    'Arizona Coyotes': 'ARI',\n",
    "    'Boston Bruins': 'BOS',\n",
    "    'Buffalo Sabres': 'BUF',\n",
    "    'Calgary Flames': 'CGY',\n",
    "    'Carolina Hurricanes': 'CAR',\n",
    "    'Chicago Blackhawks': 'CHI',\n",
    "    'Colorado Avalanche': 'COL',\n",
    "    'Columbus Blue Jackets': 'CBJ',\n",
    "    'Dallas Stars': 'DAL',\n",
    "    'Detroit Red Wings': 'DET',\n",
    "    'Edmonton Oilers': 'EDM',\n",
    "    'Florida Panthers': 'FLA',\n",
    "    'Los Angeles Kings': 'LAK',\n",
    "    'Minnesota Wild': 'MIN',\n",
    "    'Montr√©al Canadiens': 'MTL',\n",
    "    'Nashville Predators': 'NSH',\n",
    "    'New Jersey Devils': 'NJD',\n",
    "    'New York Islanders': 'NYI',\n",
    "    'New York Rangers': 'NYR',\n",
    "    'Ottawa Senators': 'OTT',\n",
    "    'Philadelphia Flyers': 'PHI',\n",
    "    'Pittsburgh Penguins': 'PIT',\n",
    "    'San Jose Sharks': 'SJS',\n",
    "    'Seattle Kraken': 'SEA',\n",
    "    'St. Louis Blues': 'STL',\n",
    "    'Tampa Bay Lightning': 'TBL',\n",
    "    'Toronto Maple Leafs': 'TOR',\n",
    "    'Vancouver Canucks': 'VAN',\n",
    "    'Vegas Golden Knights': 'VGK',\n",
    "    'Washington Capitals': 'WSH',\n",
    "    'Winnipeg Jets': 'WPG'\n",
    "}\n",
    "\n",
    "team_df['teamAbbrev'] = team_df['teamFullName'].map(nhl_teams)\n",
    "team_df.head()\n",
    "\n",
    "team_df = pd.merge(team_df, team_df, left_on=['teamAbbrev', 'gameId'], right_on=['opponentTeamAbbrev', 'gameId'], suffixes=('', '_opponent'))\n",
    "\n",
    "df = pd.merge(team_df, player_df, on=['teamAbbrev', 'gameId'])\n",
    "df = df.loc[:, ~df.columns.str.endswith('_x')]\n",
    "df = df.apply(lambda x: x.replace('_y', '') if x.name.endswith('_y') else x)\n",
    "\n",
    "for i in df.columns:\n",
    "    if i.endswith('_y'):\n",
    "        df.rename(columns={i: i.replace('_y', '')}, inplace=True)\n",
    "\n",
    "df = df.fillna(0)\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['skaterFullName'].sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load betable players for prediction & match them with averaged stats dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bum_df = pd.read_csv('../../../lib/ai_bum_list.csv') \n",
    "bum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = df[df['skaterFullName'].isin(bum_df['skaterFullName'])]\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the pred_df for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['gameId', 'penaltyKillNetPct', 'powerPlayNetPct', 'regulationAndOtWins', 'teamFullName', 'teamId', 'ties', 'winsInShootout', \n",
    "             'ppOpportunitiesPerGame', 'shGoalsAgainstPerGame', 'netPenalties', 'netPenaltiesPer60', 'pkNetGoalsPerGame', 'opponentTeamAbbrev_opponent',\n",
    "             'penaltyKillNetPct_opponent', 'regulationAndOtWins_opponent', 'teamFullName_opponent', 'teamId_opponent', 'ties_opponent', 'winsInShootout_opponent',\n",
    "             'ppNetGoalsPerGame_opponent', 'ppOpportunitiesPerGame_opponent', 'shGoalsAgainstPerGame_opponent', 'netPenaltiesPer60_opponent',\n",
    "             'netPenalties_opponent', 'pkNetGoalsPerGame_opponent', 'ppGoalsAgainstPerGame_opponent', 'shGoalsForPerGame_opponent', 'timesShorthandedPerGame_opponent',\n",
    "             'teamAbbrev_opponent', 'lastName', 'pointsPerGame', 'shootsCatches', 'skaterFullName', 'opponentTeamAbbrev', \n",
    "             'ppGoalsForPer60', 'ppIndividualSatForPer60', 'ppPointsPer60', 'ppPrimaryAssistsPer60', 'ppSecondaryAssistsPer60', 'ppShotsPer60', 'ppTimeOnIcePctPerGame',\n",
    "             'ppTimeOnIcePerGame', 'goalsForPerGame', 'teamAbbrev', 'gameDate_opponent', 'powerPlayGoalsFor', 'ppGoals', 'gameDate', 'playerId'\n",
    "            ]\n",
    "\n",
    "all_cols = pred_df.columns.to_list()\n",
    "X_cols = list(set(all_cols) - set(to_remove))\n",
    "input_df = pred_df[X_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(pred_df['positionCode'], prefix='positionCode')\n",
    "\n",
    "input_df = pd.concat([input_df, one_hot_encoded], axis=1)\n",
    "input_df = pred_df.drop('positionCode', axis=1)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(input_df['homeRoad'], prefix='homeRoad')\n",
    "\n",
    "input_df = pd.concat([input_df, one_hot_encoded], axis=1)\n",
    "input_df = pred_df.drop('homeRoad', axis=1)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(input_df['homeRoad_opponent'], prefix='homeRoad_opponent')\n",
    "\n",
    "input_df = pd.concat([input_df, one_hot_encoded], axis=1)\n",
    "input_df = input_df.drop('homeRoad_opponent', axis=1)\n",
    "\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-index to match the model input\n",
    "input_df = input_df.reindex(X_train_cols, axis=1)\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = scaler.transform(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = input_df.reshape(input_df.shape[0], T, input_df.shape[1])\n",
    "\n",
    "preds = model.predict(input_df)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = input_df.reshape(input_df.shape[0], input_df.shape[2])\n",
    "input_df = scaler.inverse_transform(input_df)\n",
    "input_df = pd.DataFrame(input_df, columns=X_train_cols)\n",
    "pred_df['predictions'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['predictions'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
