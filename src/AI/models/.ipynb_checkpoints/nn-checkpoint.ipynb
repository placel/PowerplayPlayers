{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Logan\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set at program startup\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/combined_team_player_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D', 'L', 'R', 'C'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['positionCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df['positionCode'], prefix='positionCode')\n",
    "\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "df = df.drop('positionCode', axis=1)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(df['homeRoad'], prefix='homeRoad')\n",
    "\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "df = df.drop('homeRoad', axis=1)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(df['homeRoad_opponent'], prefix='homeRoad_opponent')\n",
    "\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "df = df.drop('homeRoad_opponent', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce down to binary classes\n",
    "We want to know if the player scores a powerplay point or not. It's quite rare for a player to score 2 or more (although it may be important information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ppPoint_scored'] = df['ppPoints'].map(lambda x: 1 if x >= 1 else 0)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gameId', 'goalsAgainst', 'goalsAgainstPerGame', 'goalsFor', 'goalsForPerGame', 'losses', 'otLosses', 'penaltyKillNetPct', 'penaltyKillPct', 'pointPct']\n",
      "['powerPlayNetPct', 'powerPlayPct', 'regulationAndOtWins', 'shotsAgainstPerGame', 'shotsForPerGame', 'teamFullName', 'teamId', 'ties', 'wins', 'winsInRegulation']\n",
      "['winsInShootout', 'powerPlayGoalsFor', 'ppGoalsPerGame', 'ppNetGoals', 'ppNetGoalsPerGame', 'ppOpportunities', 'ppOpportunitiesPerGame', 'shGoalsAgainst', 'shGoalsAgainstPerGame', 'benchMinorPenalties']\n",
      "['gameMisconducts', 'majors', 'matchPenalties', 'minors', 'misconducts', 'netPenalties', 'netPenaltiesPer60', 'penalties', 'penaltiesDrawnPer60', 'penaltiesTakenPer60']\n",
      "['penaltySecondsPerGame', 'totalPenaltiesDrawn', 'pkNetGoals', 'pkNetGoalsPerGame', 'pkTimeOnIcePerGame', 'pointsPct', 'ppGoalsAgainst', 'ppGoalsAgainstPerGame', 'shGoalsFor', 'shGoalsForPerGame']\n",
      "['timesShorthanded', 'timesShorthandedPerGame', 'teamAbbrev', 'faceoffWinPct_opponent', 'gameDate_opponent', 'gamesPlayed_opponent', 'goalsAgainst_opponent', 'goalsAgainstPerGame_opponent', 'goalsFor_opponent', 'goalsForPerGame_opponent']\n",
      "['losses_opponent', 'opponentTeamAbbrev_opponent', 'otLosses_opponent', 'penaltyKillNetPct_opponent', 'penaltyKillPct_opponent', 'pointPct_opponent', 'points_opponent', 'powerPlayNetPct_opponent', 'powerPlayPct_opponent', 'regulationAndOtWins_opponent']\n",
      "['shotsAgainstPerGame_opponent', 'shotsForPerGame_opponent', 'teamFullName_opponent', 'teamId_opponent', 'ties_opponent', 'wins_opponent', 'winsInRegulation_opponent', 'winsInShootout_opponent', 'powerPlayGoalsFor_opponent', 'ppGoalsPerGame_opponent']\n",
      "['ppNetGoals_opponent', 'ppNetGoalsPerGame_opponent', 'ppOpportunities_opponent', 'ppOpportunitiesPerGame_opponent', 'ppTimeOnIcePerGame_opponent', 'shGoalsAgainst_opponent', 'shGoalsAgainstPerGame_opponent', 'benchMinorPenalties_opponent', 'gameMisconducts_opponent', 'majors_opponent']\n",
      "['matchPenalties_opponent', 'minors_opponent', 'misconducts_opponent', 'netPenalties_opponent', 'netPenaltiesPer60_opponent', 'penalties_opponent', 'penaltiesDrawnPer60_opponent', 'penaltiesTakenPer60_opponent', 'penaltyMinutes_opponent', 'penaltySecondsPerGame_opponent']\n",
      "['totalPenaltiesDrawn_opponent', 'pkNetGoals_opponent', 'pkNetGoalsPerGame_opponent', 'pkTimeOnIcePerGame_opponent', 'pointsPct_opponent', 'ppGoalsAgainst_opponent', 'ppGoalsAgainstPerGame_opponent', 'shGoalsFor_opponent', 'shGoalsForPerGame_opponent', 'timesShorthanded_opponent']\n",
      "['timesShorthandedPerGame_opponent', 'teamAbbrev_opponent', 'assists', 'evGoals', 'evPoints', 'faceoffWinPct', 'gameWinningGoals', 'gamesPlayed', 'goals', 'lastName']\n",
      "['otGoals', 'penaltyMinutes', 'playerId', 'plusMinus', 'points', 'pointsPerGame', 'ppGoals', 'ppPoints', 'shGoals', 'shPoints']\n",
      "['shootingPct', 'shootsCatches', 'shots', 'skaterFullName', 'timeOnIcePerGame', 'gameDate', 'opponentTeamAbbrev', 'ppAssists', 'ppGoalsForPer60', 'ppGoalsPer60']\n",
      "['ppIndividualSatFor', 'ppIndividualSatForPer60', 'ppPointsPer60', 'ppPrimaryAssists', 'ppPrimaryAssistsPer60', 'ppSecondaryAssists', 'ppSecondaryAssistsPer60', 'ppShootingPct', 'ppShots', 'ppShotsPer60']\n",
      "['ppTimeOnIce', 'ppTimeOnIcePctPerGame', 'ppTimeOnIcePerGame', 'positionCode_C', 'positionCode_D', 'positionCode_L', 'positionCode_R', 'homeRoad_H', 'homeRoad_R', 'homeRoad_opponent_H']\n"
     ]
    }
   ],
   "source": [
    "col_len = len(df.columns)\n",
    "count = 0\n",
    "for i in range(16):\n",
    "    print(df.columns.to_list()[count:count+10])\n",
    "    if count >= col_len:\n",
    "        break\n",
    "    count = count + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "162\n",
      "426309\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goalsAgainst_opponent</th>\n",
       "      <th>ppShootingPct</th>\n",
       "      <th>shotsAgainstPerGame</th>\n",
       "      <th>shGoals</th>\n",
       "      <th>shotsForPerGame</th>\n",
       "      <th>powerPlayNetPct_opponent</th>\n",
       "      <th>goalsFor_opponent</th>\n",
       "      <th>wins_opponent</th>\n",
       "      <th>gamesPlayed_opponent</th>\n",
       "      <th>homeRoad_opponent_H</th>\n",
       "      <th>...</th>\n",
       "      <th>positionCode_R</th>\n",
       "      <th>shotsForPerGame_opponent</th>\n",
       "      <th>ppOpportunities</th>\n",
       "      <th>goalsAgainst</th>\n",
       "      <th>ppGoalsAgainst</th>\n",
       "      <th>losses_opponent</th>\n",
       "      <th>timesShorthanded</th>\n",
       "      <th>penaltyMinutes</th>\n",
       "      <th>penaltyKillPct</th>\n",
       "      <th>homeRoad_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.333</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   goalsAgainst_opponent  ppShootingPct  shotsAgainstPerGame  shGoals  \\\n",
       "0                      4          0.000                 37.0        0   \n",
       "1                      4          0.333                 37.0        0   \n",
       "2                      4          0.000                 37.0        0   \n",
       "3                      4          0.000                 37.0        0   \n",
       "4                      4          0.000                 37.0        1   \n",
       "\n",
       "   shotsForPerGame  powerPlayNetPct_opponent  goalsFor_opponent  \\\n",
       "0             38.0                     -0.25                  3   \n",
       "1             38.0                     -0.25                  3   \n",
       "2             38.0                     -0.25                  3   \n",
       "3             38.0                     -0.25                  3   \n",
       "4             38.0                     -0.25                  3   \n",
       "\n",
       "   wins_opponent  gamesPlayed_opponent  homeRoad_opponent_H  ...  \\\n",
       "0              0                     1                 True  ...   \n",
       "1              0                     1                 True  ...   \n",
       "2              0                     1                 True  ...   \n",
       "3              0                     1                 True  ...   \n",
       "4              0                     1                 True  ...   \n",
       "\n",
       "   positionCode_R  shotsForPerGame_opponent  ppOpportunities  goalsAgainst  \\\n",
       "0           False                      37.0                7             3   \n",
       "1           False                      37.0                7             3   \n",
       "2           False                      37.0                7             3   \n",
       "3            True                      37.0                7             3   \n",
       "4           False                      37.0                7             3   \n",
       "\n",
       "   ppGoalsAgainst  losses_opponent  timesShorthanded  penaltyMinutes  \\\n",
       "0               0                1                 4               2   \n",
       "1               0                1                 4               2   \n",
       "2               0                1                 4               0   \n",
       "3               0                1                 4               0   \n",
       "4               0                1                 4               0   \n",
       "\n",
       "   penaltyKillPct  homeRoad_R  \n",
       "0             1.0        True  \n",
       "1             1.0        True  \n",
       "2             1.0        True  \n",
       "3             1.0        True  \n",
       "4             1.0        True  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_remove = ['gameId', 'penaltyKillNetPct', 'powerPlayNetPct', 'regulationAndOtWins', 'teamFullName', 'teamId', 'ties', 'winsInShootout', \n",
    "             'ppOpportunitiesPerGame', 'shGoalsAgainstPerGame', 'netPenalties', 'netPenaltiesPer60', 'pkNetGoalsPerGame', 'opponentTeamAbbrev_opponent',\n",
    "             'penaltyKillNetPct_opponent', 'regulationAndOtWins_opponent', 'teamFullName_opponent', 'teamId_opponent', 'ties_opponent', 'winsInShootout_opponent',\n",
    "             'ppNetGoalsPerGame_opponent', 'ppOpportunitiesPerGame_opponent', 'shGoalsAgainstPerGame_opponent', 'netPenaltiesPer60_opponent',\n",
    "             'netPenalties_opponent', 'pkNetGoalsPerGame_opponent', 'ppGoalsAgainstPerGame_opponent', 'shGoalsForPerGame_opponent', 'timesShorthandedPerGame_opponent',\n",
    "             'teamAbbrev_opponent', 'lastName', 'playerId', 'pointsPerGame', 'shootsCatches', 'skaterFullName', 'gameDate', 'opponentTeamAbbrev', \n",
    "             'ppGoalsForPer60', 'ppIndividualSatForPer60', 'ppPointsPer60', 'ppPrimaryAssistsPer60', 'ppSecondaryAssistsPer60', 'ppShotsPer60', 'ppTimeOnIcePctPerGame',\n",
    "             'ppTimeOnIcePerGame', 'goalsForPerGame', 'teamAbbrev', 'gameDate_opponent', 'gameDate', 'powerPlayGoalsFor', 'ppGoals'\n",
    "            ]\n",
    "\n",
    "print(len(to_remove))\n",
    "all_cols = df.columns.to_list()\n",
    "\n",
    "print(len(all_cols))\n",
    "X_cols = list(set(all_cols) - set(to_remove))\n",
    "\n",
    "X = df[X_cols]\n",
    "print(len(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Logan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m target_variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppPoint_scored\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Logan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_variable = 'ppPoint_scored'\n",
    "\n",
    "# Step 2: Inspect class distribution\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(df[target_variable].value_counts())\n",
    "\n",
    "# Step 3: Split features and target variable\n",
    "X = X.drop(target_variable, axis=1)\n",
    "y = df[target_variable]\n",
    "\n",
    "# Step 4: Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Step 5: Use the resampled dataset\n",
    "# For example, you can split the resampled dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cols = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping for LSTM\n",
    "T = 1\n",
    "X_train = X_train.reshape(X_train.shape[0], T, X_train.shape[1])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(dropout_rate),\n",
    "    # LSTM(128, input_shape=(X_train.shape[0], 1, X_train.shape[2])),\n",
    "    LSTM(128, input_shape=(X_train.shape[0], T, X_train.shape[2])),\n",
    "    # LSTM(128, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(dropout_rate),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(dropout_rate),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(), 'accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1, callbacks=[callback], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Adjust the threshold\n",
    "threshold = 0.9 # You can experiment with different threshold values\n",
    "y_pred_labels = (y_pred_probs > threshold).astype(int)\n",
    "\n",
    "print(f'threshold of {threshold*100}%')\n",
    "print(classification_report(y_test, y_pred_labels))\n",
    "\n",
    "y_pred = model.predict(X_test) \n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "print('Regular threshold')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['precision'], label='Training Precision')\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(y_pred, label='Testing Precision')\n",
    "# plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player List Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Averages of Players and Teams, then combine into 1 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df = pd.read_csv('../data/database/player-database.csv')\n",
    "team_df = pd.read_csv('../data/database/team-database.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the average of each players stats for the last 5 games, then take the last occurance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have loaded your dataframe into a variable called 'nhl_stats_df'\n",
    "\n",
    "# Sort the dataframe by player and date\n",
    "nhl_stats_df = player_df.sort_values(by=['playerId', 'gameDate'])\n",
    "\n",
    "# Define a function to calculate the rolling average for numeric columns\n",
    "def calc_rolling_avg(group):\n",
    "    return group.rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Split the dataframe into numeric and non-numeric parts\n",
    "numeric_columns = nhl_stats_df.select_dtypes(include='number').columns\n",
    "numeric_columns = numeric_columns.drop('gameId')\n",
    "non_numeric_columns = [col for col in nhl_stats_df.columns if col not in numeric_columns]\n",
    "\n",
    "# Calculate the rolling average for numeric columns for each player\n",
    "rolling_avg_numeric_df = nhl_stats_df.groupby('playerId', group_keys=False)[numeric_columns].apply(calc_rolling_avg)\n",
    "\n",
    "# Merge rolling average with non-numeric columns\n",
    "rolling_avg_df = pd.concat([nhl_stats_df[non_numeric_columns], rolling_avg_numeric_df], axis=1)\n",
    "player_df = rolling_avg_df.groupby('playerId').tail(1) ## get the last game for each player \n",
    "player_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the average for each teams stats over the last 5 games, and return the last occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have loaded your dataframe into a variable called 'nhl_stats_df'\n",
    "\n",
    "# Sort the dataframe by player and date\n",
    "nhl_stats_df = team_df.sort_values(by=['teamId', 'gameDate'])\n",
    "\n",
    "# Define a function to calculate the rolling average for numeric columns\n",
    "def calc_rolling_avg(group):\n",
    "    return group.rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Split the dataframe into numeric and non-numeric parts\n",
    "numeric_columns = nhl_stats_df.select_dtypes(include='number').columns\n",
    "numeric_columns = numeric_columns.drop('gameId')\n",
    "non_numeric_columns = [col for col in nhl_stats_df.columns if col not in numeric_columns]\n",
    "\n",
    "# Calculate the rolling average for numeric columns for each player\n",
    "rolling_avg_numeric_df = nhl_stats_df.groupby('teamId', group_keys=False)[numeric_columns].apply(calc_rolling_avg)\n",
    "\n",
    "# Merge rolling average with non-numeric columns\n",
    "rolling_avg_df = pd.concat([nhl_stats_df[non_numeric_columns], rolling_avg_numeric_df], axis=1)\n",
    "team_df = rolling_avg_df.groupby('teamId').tail(1) ## Get the last occurance of each teams stats and save them into the orginal team_df\n",
    "team_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group player stats, team stats, and opposing team stats into one dataframe for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhl_teams = {\n",
    "    'Anaheim Ducks': 'ANA',\n",
    "    'Arizona Coyotes': 'ARI',\n",
    "    'Boston Bruins': 'BOS',\n",
    "    'Buffalo Sabres': 'BUF',\n",
    "    'Calgary Flames': 'CGY',\n",
    "    'Carolina Hurricanes': 'CAR',\n",
    "    'Chicago Blackhawks': 'CHI',\n",
    "    'Colorado Avalanche': 'COL',\n",
    "    'Columbus Blue Jackets': 'CBJ',\n",
    "    'Dallas Stars': 'DAL',\n",
    "    'Detroit Red Wings': 'DET',\n",
    "    'Edmonton Oilers': 'EDM',\n",
    "    'Florida Panthers': 'FLA',\n",
    "    'Los Angeles Kings': 'LAK',\n",
    "    'Minnesota Wild': 'MIN',\n",
    "    'Montréal Canadiens': 'MTL',\n",
    "    'Nashville Predators': 'NSH',\n",
    "    'New Jersey Devils': 'NJD',\n",
    "    'New York Islanders': 'NYI',\n",
    "    'New York Rangers': 'NYR',\n",
    "    'Ottawa Senators': 'OTT',\n",
    "    'Philadelphia Flyers': 'PHI',\n",
    "    'Pittsburgh Penguins': 'PIT',\n",
    "    'San Jose Sharks': 'SJS',\n",
    "    'Seattle Kraken': 'SEA',\n",
    "    'St. Louis Blues': 'STL',\n",
    "    'Tampa Bay Lightning': 'TBL',\n",
    "    'Toronto Maple Leafs': 'TOR',\n",
    "    'Vancouver Canucks': 'VAN',\n",
    "    'Vegas Golden Knights': 'VGK',\n",
    "    'Washington Capitals': 'WSH',\n",
    "    'Winnipeg Jets': 'WPG'\n",
    "}\n",
    "\n",
    "team_df['teamAbbrev'] = team_df['teamFullName'].map(nhl_teams)\n",
    "team_df.head()\n",
    "\n",
    "team_df = pd.merge(team_df, team_df, left_on=['teamAbbrev', 'gameId'], right_on=['opponentTeamAbbrev', 'gameId'], suffixes=('', '_opponent'))\n",
    "\n",
    "df = pd.merge(team_df, player_df, on=['teamAbbrev', 'gameId'])\n",
    "df = df.loc[:, ~df.columns.str.endswith('_x')]\n",
    "df = df.apply(lambda x: x.replace('_y', '') if x.name.endswith('_y') else x)\n",
    "\n",
    "for i in df.columns:\n",
    "    if i.endswith('_y'):\n",
    "        df.rename(columns={i: i.replace('_y', '')}, inplace=True)\n",
    "\n",
    "df = df.fillna(0)\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['skaterFullName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load betable players for prediction & match them with averaged stats dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bum_df = pd.read_csv('../../../lib/ai_bum_list.csv') \n",
    "bum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = df[df['skaterFullName'].isin(bum_df['skaterFullName'])]\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the pred_df for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['gameId', 'penaltyKillNetPct', 'powerPlayNetPct', 'regulationAndOtWins', 'teamFullName', 'teamId', 'ties', 'winsInShootout', \n",
    "             'ppOpportunitiesPerGame', 'shGoalsAgainstPerGame', 'netPenalties', 'netPenaltiesPer60', 'pkNetGoalsPerGame', 'opponentTeamAbbrev_opponent',\n",
    "             'penaltyKillNetPct_opponent', 'regulationAndOtWins_opponent', 'teamFullName_opponent', 'teamId_opponent', 'ties_opponent', 'winsInShootout_opponent',\n",
    "             'ppNetGoalsPerGame_opponent', 'ppOpportunitiesPerGame_opponent', 'shGoalsAgainstPerGame_opponent', 'netPenaltiesPer60_opponent',\n",
    "             'netPenalties_opponent', 'pkNetGoalsPerGame_opponent', 'ppGoalsAgainstPerGame_opponent', 'shGoalsForPerGame_opponent', 'timesShorthandedPerGame_opponent',\n",
    "             'teamAbbrev_opponent', 'lastName', 'pointsPerGame', 'shootsCatches', 'skaterFullName', 'opponentTeamAbbrev', \n",
    "             'ppGoalsForPer60', 'ppIndividualSatForPer60', 'ppPointsPer60', 'ppPrimaryAssistsPer60', 'ppSecondaryAssistsPer60', 'ppShotsPer60', 'ppTimeOnIcePctPerGame',\n",
    "             'ppTimeOnIcePerGame', 'goalsForPerGame', 'teamAbbrev', 'gameDate_opponent', 'powerPlayGoalsFor', 'ppGoals', 'gameDate', 'playerId'\n",
    "            ]\n",
    "\n",
    "all_cols = pred_df.columns.to_list()\n",
    "X_cols = list(set(all_cols) - set(to_remove))\n",
    "input_df = pred_df[X_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(pred_df['positionCode'], prefix='positionCode')\n",
    "\n",
    "input_df = pd.concat([input_df, one_hot_encoded], axis=1)\n",
    "input_df = pred_df.drop('positionCode', axis=1)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(input_df['homeRoad'], prefix='homeRoad')\n",
    "\n",
    "input_df = pd.concat([input_df, one_hot_encoded], axis=1)\n",
    "input_df = pred_df.drop('homeRoad', axis=1)\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(input_df['homeRoad_opponent'], prefix='homeRoad_opponent')\n",
    "\n",
    "input_df = pd.concat([input_df, one_hot_encoded], axis=1)\n",
    "input_df = input_df.drop('homeRoad_opponent', axis=1)\n",
    "\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-index to match the model input\n",
    "input_df = input_df.reindex(X_train_cols, axis=1)\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = scaler.transform(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(input_df)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = scaler.inverse_transform(input_df)\n",
    "input_df = pd.DataFrame(input_df, columns=X_train_cols)\n",
    "pred_df['predictions'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
